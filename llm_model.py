# MODEL_NAME = "mistralai/Mistral-7B-Instruct-v0.1"         # ~14GB, 32K context
MODEL_NAME = "unsloth/mistral-7b-instruct-v0.3-bnb-4bit"  # ~4GB, 32K context (quantized)
# MODEL_NAME = "meta-llama/Llama-3.2-1B-Instruct"           # ~2GB, 4K context
# MODEL_NAME = "Qwen/Qwen2-1.5B-Instruct"                     # ~3GB, 32K context